{
  "hash": "c220e06f94fe7ebd9a3d87639c8add2c",
  "result": {
    "markdown": "---\ntitle: \"Dictionary & Text Analysis\"\n---\n\n::: {.cell}\n\n```{.r .cell-code}\n# Step 1: Load data from a file\nload(\"~/UMD/R/BukeleSince062020.RData\")\n\n# Step 2: Load required libraries\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.3     ‚úî readr     2.1.4\n‚úî forcats   1.0.0     ‚úî stringr   1.5.0\n‚úî ggplot2   3.4.3     ‚úî tibble    3.2.1\n‚úî lubridate 1.9.2     ‚úî tidyr     1.3.0\n‚úî purrr     1.0.2     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n\n```{.r .cell-code}\nlibrary(rtweet)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'rtweet'\n\nThe following object is masked from 'package:purrr':\n\n    flatten\n```\n:::\n\n```{.r .cell-code}\nlibrary(stringr)\nlibrary(epiDisplay)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: foreign\nLoading required package: survival\nLoading required package: MASS\n\nAttaching package: 'MASS'\n\nThe following object is masked from 'package:dplyr':\n\n    select\n\nLoading required package: nnet\n\nAttaching package: 'epiDisplay'\n\nThe following object is masked from 'package:ggplot2':\n\n    alpha\n```\n:::\n\n```{.r .cell-code}\nlibrary(tidytext)\nlibrary(igraph)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'igraph'\n\nThe following objects are masked from 'package:lubridate':\n\n    %--%, union\n\nThe following objects are masked from 'package:dplyr':\n\n    as_data_frame, groups, union\n\nThe following objects are masked from 'package:purrr':\n\n    compose, simplify\n\nThe following object is masked from 'package:tidyr':\n\n    crossing\n\nThe following object is masked from 'package:tibble':\n\n    as_data_frame\n\nThe following objects are masked from 'package:stats':\n\n    decompose, spectrum\n\nThe following object is masked from 'package:base':\n\n    union\n```\n:::\n\n```{.r .cell-code}\nlibrary(reshape2)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'reshape2'\n\nThe following object is masked from 'package:tidyr':\n\n    smiths\n```\n:::\n\n```{.r .cell-code}\nlibrary(haven)\nlibrary(foreign)\nlibrary(lubridate)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tm)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: NLP\n\nAttaching package: 'NLP'\n\nThe following object is masked from 'package:ggplot2':\n\n    annotate\n```\n:::\n\n```{.r .cell-code}\nlibrary(quanteda)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nPackage version: 3.3.1\nUnicode version: 13.0\nICU version: 69.1\nParallel computing: 12 of 12 threads used.\nSee https://quanteda.io for tutorials and examples.\n\nAttaching package: 'quanteda'\n\nThe following object is masked from 'package:tm':\n\n    stopwords\n\nThe following objects are masked from 'package:NLP':\n\n    meta, meta<-\n```\n:::\n\n```{.r .cell-code}\n# Step 3: Create a sample DataFrame\nbukele <- boca.df[sample(nrow(boca.df), 10000),]\n\n# Step 4: Display column names of the DataFrame\ncolnames(bukele)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"HubTweetID\"              \"text\"                   \n [3] \"AuthTweetID\"             \"AuthorityTweetType\"     \n [5] \"timeRT\"                  \"Conversation\"           \n [7] \"Lang\"                    \"source\"                 \n [9] \"hubid\"                   \"retweets\"               \n[11] \"replies\"                 \"likes\"                  \n[13] \"quotes\"                  \"domainName\"             \n[15] \"authid\"                  \"name_auth\"              \n[17] \"timeT\"                   \"name_hub\"               \n[19] \"fullname_hub\"            \"location_hub\"           \n[21] \"numberTweets_hub\"        \"friends_hub\"            \n[23] \"followers_hub\"           \"account_created_hub\"    \n[25] \"account_verified_hub\"    \"account_description_hub\"\n[27] \"account_protected_hub\"  \n```\n:::\n\n```{.r .cell-code}\n# Step 5: Create a quanteda corpus\nbukele_corp <- corpus(bukele)\n\n# Step 6: Display a subset of the corpus\nbukele_corp[1:4]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCorpus consisting of 4 documents and 26 docvars.\ntext1 :\n\"@nayibbukele üî•üî•\"\n\ntext2 :\n\"RT @nayibbukele: Anuncia 17 expedientes abiertos contra el G...\"\n\ntext3 :\n\"RT @ciprianreyes: El respeto al derecho ajeno es la paz Beni...\"\n\ntext4 :\n\"RT @Azulyblanco100: A 40 a√±os de que se perpetr√≥ la masacre ...\"\n```\n:::\n\n```{.r .cell-code}\n# Step 7: Display summary information of the corpus\nsummary(bukele_corp) %>% head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Text Types Tokens Sentences          HubTweetID         AuthTweetID\n1 text1     2      3         1 1453642992842121222 1453461587948445697\n2 text2    21     22         1 1330982774736625667 1330975827111108609\n3 text3    26     28         3 1442141412833644545 1441952826003898372\n4 text4    25     26         1 1469434798129225733 1469434767749918724\n5 text5    20     20         2 1438206650310176773 1438147874240532482\n6 text6    23     24         1 1340497143447040001 1340447216348086273\n  AuthorityTweetType                   timeRT        Conversation Lang\n1         replied_to 2021-10-28T08:41:11.000Z 1453461587948445697  und\n2          retweeted 2020-11-23T21:13:16.000Z 1330982774736625667   es\n3          retweeted 2021-09-26T14:58:01.000Z 1442141412833644545   es\n4          retweeted 2021-12-10T22:32:11.000Z 1469434798129225733   es\n5         replied_to 2021-09-15T18:22:40.000Z 1438147874240532482   es\n6          retweeted 2020-12-20T03:19:58.000Z 1340497143447040001   es\n               source              hubid retweets replies likes quotes\n1  Twitter for iPhone          354499396        0       0     0      0\n2  Twitter for iPhone         2600369045      641       0     0      0\n3  Twitter for iPhone          252922122       67       0     0      0\n4 Twitter for Android 927366179856973824       18       0     0      0\n5 Twitter for Android          834191713        0       0     0      0\n6 Twitter for Android         2372298773       26       0     0      0\n          domainName              authid      name_auth\n1                               20736511    nayibbukele\n2 Ongoing News Story            20736511    nayibbukele\n3                             3068911604   ciprianreyes\n4                    1458928257374556161 Azulyblanco100\n5                              759774162 MigueVaquerano\n6                    1312452088547487744   NoticieroSLV\n                     timeT      name_hub fullname_hub              location_hub\n1                     <NA>     VladRotar      vladxlr                 Metaverse\n2                     <NA>      TinoRubi    Tino Rubi            new york city \n3 2021-09-26T02:28:38.000Z gerberfuentes       Gerber                 Texas USA\n4 2021-12-10T22:32:04.000Z  AnonimoSV503   Anonimo.sv San Salvador, El Salvador\n5 2021-09-15T14:29:07.000Z   sestrada28_      Sof√≠a‚≠ê                      <NA>\n6 2020-12-20T00:01:35.000Z  Lui5_8onilla          LAB     Usulut√°n, El Salvador\n  numberTweets_hub friends_hub followers_hub      account_created_hub\n1             1256         865           542 2011-08-13T20:37:50.000Z\n2             7421         239           114 2014-06-11T07:07:52.000Z\n3             7298         434           150 2011-02-16T05:32:30.000Z\n4           151667        5497         37488 2017-11-06T02:45:01.000Z\n5             5653         106           208 2012-09-19T21:41:59.000Z\n6            30386         532           145 2014-03-01T02:41:11.000Z\n  account_verified_hub\n1                FALSE\n2                FALSE\n3                FALSE\n4                FALSE\n5                FALSE\n6                FALSE\n                                                                                                                                          account_description_hub\n1 Founder @SlavaUkrainiNFT Web3 #BUIDLer & #NFTDegen Crypto #OG since 2017 #Metasaurs #Metasaursfollowmetasaurs #LazyLionsNFT #CunningWolfSociety #TrippyToadzNFT\n2                                                                                                                                                                \n3                                                                                                                                                                \n4                                                Me encanta la sensaci√≥n de ser an√≥nimo en una ciudad en la que nunca hab√≠a estado | Parody Account | #TrolConDUI\n5                                                                                                                        Determinada y persistente || Juan 11:40.\n6  Me gusta el gimnasio, salir en motocicleta, me encanta la playa, la monta√±a, los lagos, me gusta recorrer mi peque√±o pa√≠s. Pronto inicio como internacional üòâ.\n  account_protected_hub\n1                 FALSE\n2                 FALSE\n3                 FALSE\n4                 FALSE\n5                 FALSE\n6                 FALSE\n```\n:::\n\n```{.r .cell-code}\n# Step 8: Tokenize the corpus into words\ntokens(bukele_corp, \"word\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTokens consisting of 10,000 documents and 26 docvars.\ntext1 :\n[1] \"@nayibbukele\" \"üî•\"           \"üî•\"          \n\ntext2 :\n [1] \"RT\"           \"@nayibbukele\" \":\"            \"Anuncia\"      \"17\"          \n [6] \"expedientes\"  \"abiertos\"     \"contra\"       \"el\"           \"Gobierno\"    \n[11] \",\"            \"flanqueado\"  \n[ ... and 10 more ]\n\ntext3 :\n [1] \"RT\"            \"@ciprianreyes\" \":\"             \"El\"           \n [5] \"respeto\"       \"al\"            \"derecho\"       \"ajeno\"        \n [9] \"es\"            \"la\"            \"paz\"           \"Benito\"       \n[ ... and 16 more ]\n\ntext4 :\n [1] \"RT\"              \"@Azulyblanco100\" \":\"               \"A\"              \n [5] \"40\"              \"a√±os\"            \"de\"              \"que\"            \n [9] \"se\"              \"perpetr√≥\"        \"la\"              \"masacre\"        \n[ ... and 14 more ]\n\ntext5 :\n [1] \"@MigueVaquerano\" \"@nayibbukele\"    \"¬ø\"               \"Acaso\"          \n [5] \"no\"              \"es\"              \"lo\"              \"que\"            \n [9] \"ustedes\"         \"hacen\"           \"a\"               \"diario\"         \n[ ... and 8 more ]\n\ntext6 :\n [1] \"RT\"            \"@NoticieroSLV\" \":\"             \"El\"           \n [5] \"Presidente\"    \"@nayibbukele\"  \"dijo\"          \"que\"          \n [9] \"esta\"          \"es\"            \"una\"           \"muestra\"      \n[ ... and 12 more ]\n\n[ reached max_ndoc ... 9,994 more documents ]\n```\n:::\n\n```{.r .cell-code}\nbukele_toks <- tokens(bukele_corp)\n\n# Step 9: Create a document-feature matrix (dfm) from tokens\nbukele_dfm  <- dfm(bukele_toks)\nbukele_dfm\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDocument-feature matrix of: 10,000 documents, 26,427 features (99.92% sparse) and 26 docvars.\n       features\ndocs    @nayibbukeleüî• rt : anuncia 17 expedientes abiertos contra el\n  text1            1 2  0 0       0  0           0        0      0  0\n  text2            1 0  1 1       1  1           1        1      1  1\n  text3            1 0  1 1       0  0           0        0      0  2\n  text4            1 0  1 1       0  0           0        0      0  2\n  text5            1 0  0 0       0  0           0        0      0  0\n  text6            1 0  1 1       0  0           0        0      0  2\n[ reached max_ndoc ... 9,994 more documents, reached max_nfeat ... 26,417 more features ]\n```\n:::\n\n```{.r .cell-code}\n# Step 10: Display top features in the dfm\ntopfeatures(bukele_dfm, 100)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  @nayibbukele              .             de              ,              : \n          9044           7542           7145           6986           6600 \n            rt             el            que              ‚Ä¶             la \n          6032           5107           4943           4453           4404 \n             a              y             en            los             no \n          3924           3365           2828           2374           2281 \n    presidente             es            por              !            del \n          1760           1639           1586           1499           1491 \n            se           para            con             un             lo \n          1486           1444           1263           1201           1187 \n           las              ?             al            the             ü§£ \n          1168           1104            918            914            848 \n      salvador            una              ‚Äú             su             üá∏üáª \n           813            773            744            691            664 \n          como             si             ya              \"            m√°s \n           634            626            607            606            578 \n          este             le           pero       gobierno              ¬ø \n           569            552            520            504            487 \n            to         pueblo        nuestro             üòÇ              ‚Äù \n           483            468            458            438            436 \n          pa√≠s           esta            les             me            son \n           420            411            410            405            402 \n            of           solo              |           est√°           todo \n           390            383            381            367            366 \n         todos             is              o            hay            and \n           364            355            335            329            327 \n            in       #bitcoin    @asambleasv            nos        gracias \n           327            323            321            317            312 \n           sus             ha            you             mi              $ \n           311            304            304            301            295 \n        cuando @presidenciasv            eso              q         porque \n           288            286            283            278            265 \n          dios             te          est√°n              (          tiene \n           261            257            247            247            244 \n            ni              ¬°          ahora              %           a√±os \n           237            236            233            233            227 \n    @waraujo64            hoy            han            as√≠            ser \n           223            216            216            216            214 \n             )         contra            d√≠a            sin              1 \n           214            213            208            205            201 \n```\n:::\n\n```{.r .cell-code}\n# Step 11: Pre-processing - Analyze the structure of dfm and tokens\n\n# - Display the number of tokens\nntoken(bukele_toks) %>% head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntext1 text2 text3 text4 text5 text6 \n    3    22    28    26    20    24 \n```\n:::\n\n```{.r .cell-code}\n# - Display the number of features in a dfm\nnfeat(bukele_dfm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 26427\n```\n:::\n\n```{.r .cell-code}\n# - Display the most frequent features\ntopfeatures(bukele_dfm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n@nayibbukele            .           de            ,            :           rt \n        9044         7542         7145         6986         6600         6032 \n          el          que            ‚Ä¶           la \n        5107         4943         4453         4404 \n```\n:::\n\n```{.r .cell-code}\n# - Display the number of documents\nndoc(bukele_dfm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 10000\n```\n:::\n\n```{.r .cell-code}\n# - Display names of features as a vector\nfeatnames(bukele_dfm) %>% head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"@nayibbukele\" \"üî•\"           \"rt\"           \":\"            \"anuncia\"     \n[6] \"17\"          \n```\n:::\n\n```{.r .cell-code}\n# - Display frequency of features as a vector\nfeatfreq(bukele_dfm) %>% head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n@nayibbukele           üî•           rt            :      anuncia           17 \n        9044           56         6032         6600           19            9 \n```\n:::\n\n```{.r .cell-code}\n# Step 12: Restrict feature definitions\n\n# - Display the current number of features in dfm\nnfeat(bukele_dfm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 26427\n```\n:::\n\n```{.r .cell-code}\n# - Restrict feature definition by removing punctuation, numbers, and symbols\nbukele_toks <- tokens(bukele_corp, remove_punct = T, remove_numbers = T, remove_symbols = T)\n\n# - Display English and Spanish stopwords\nstopwords(\"en\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  [1] \"i\"          \"me\"         \"my\"         \"myself\"     \"we\"        \n  [6] \"our\"        \"ours\"       \"ourselves\"  \"you\"        \"your\"      \n [11] \"yours\"      \"yourself\"   \"yourselves\" \"he\"         \"him\"       \n [16] \"his\"        \"himself\"    \"she\"        \"her\"        \"hers\"      \n [21] \"herself\"    \"it\"         \"its\"        \"itself\"     \"they\"      \n [26] \"them\"       \"their\"      \"theirs\"     \"themselves\" \"what\"      \n [31] \"which\"      \"who\"        \"whom\"       \"this\"       \"that\"      \n [36] \"these\"      \"those\"      \"am\"         \"is\"         \"are\"       \n [41] \"was\"        \"were\"       \"be\"         \"been\"       \"being\"     \n [46] \"have\"       \"has\"        \"had\"        \"having\"     \"do\"        \n [51] \"does\"       \"did\"        \"doing\"      \"would\"      \"should\"    \n [56] \"could\"      \"ought\"      \"i'm\"        \"you're\"     \"he's\"      \n [61] \"she's\"      \"it's\"       \"we're\"      \"they're\"    \"i've\"      \n [66] \"you've\"     \"we've\"      \"they've\"    \"i'd\"        \"you'd\"     \n [71] \"he'd\"       \"she'd\"      \"we'd\"       \"they'd\"     \"i'll\"      \n [76] \"you'll\"     \"he'll\"      \"she'll\"     \"we'll\"      \"they'll\"   \n [81] \"isn't\"      \"aren't\"     \"wasn't\"     \"weren't\"    \"hasn't\"    \n [86] \"haven't\"    \"hadn't\"     \"doesn't\"    \"don't\"      \"didn't\"    \n [91] \"won't\"      \"wouldn't\"   \"shan't\"     \"shouldn't\"  \"can't\"     \n [96] \"cannot\"     \"couldn't\"   \"mustn't\"    \"let's\"      \"that's\"    \n[101] \"who's\"      \"what's\"     \"here's\"     \"there's\"    \"when's\"    \n[106] \"where's\"    \"why's\"      \"how's\"      \"a\"          \"an\"        \n[111] \"the\"        \"and\"        \"but\"        \"if\"         \"or\"        \n[116] \"because\"    \"as\"         \"until\"      \"while\"      \"of\"        \n[121] \"at\"         \"by\"         \"for\"        \"with\"       \"about\"     \n[126] \"against\"    \"between\"    \"into\"       \"through\"    \"during\"    \n[131] \"before\"     \"after\"      \"above\"      \"below\"      \"to\"        \n[136] \"from\"       \"up\"         \"down\"       \"in\"         \"out\"       \n[141] \"on\"         \"off\"        \"over\"       \"under\"      \"again\"     \n[146] \"further\"    \"then\"       \"once\"       \"here\"       \"there\"     \n[151] \"when\"       \"where\"      \"why\"        \"how\"        \"all\"       \n[156] \"any\"        \"both\"       \"each\"       \"few\"        \"more\"      \n[161] \"most\"       \"other\"      \"some\"       \"such\"       \"no\"        \n[166] \"nor\"        \"not\"        \"only\"       \"own\"        \"same\"      \n[171] \"so\"         \"than\"       \"too\"        \"very\"       \"will\"      \n```\n:::\n\n```{.r .cell-code}\nstopwords(\"es\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  [1] \"de\"           \"la\"           \"que\"          \"el\"           \"en\"          \n  [6] \"y\"            \"a\"            \"los\"          \"del\"          \"se\"          \n [11] \"las\"          \"por\"          \"un\"           \"para\"         \"con\"         \n [16] \"no\"           \"una\"          \"su\"           \"al\"           \"lo\"          \n [21] \"como\"         \"m√°s\"          \"pero\"         \"sus\"          \"le\"          \n [26] \"ya\"           \"o\"            \"este\"         \"s√≠\"           \"porque\"      \n [31] \"esta\"         \"entre\"        \"cuando\"       \"muy\"          \"sin\"         \n [36] \"sobre\"        \"tambi√©n\"      \"me\"           \"hasta\"        \"hay\"         \n [41] \"donde\"        \"quien\"        \"desde\"        \"todo\"         \"nos\"         \n [46] \"durante\"      \"todos\"        \"uno\"          \"les\"          \"ni\"          \n [51] \"contra\"       \"otros\"        \"ese\"          \"eso\"          \"ante\"        \n [56] \"ellos\"        \"e\"            \"esto\"         \"m√≠\"           \"antes\"       \n [61] \"algunos\"      \"qu√©\"          \"unos\"         \"yo\"           \"otro\"        \n [66] \"otras\"        \"otra\"         \"√©l\"           \"tanto\"        \"esa\"         \n [71] \"estos\"        \"mucho\"        \"quienes\"      \"nada\"         \"muchos\"      \n [76] \"cual\"         \"poco\"         \"ella\"         \"estar\"        \"estas\"       \n [81] \"algunas\"      \"algo\"         \"nosotros\"     \"mi\"           \"mis\"         \n [86] \"t√∫\"           \"te\"           \"ti\"           \"tu\"           \"tus\"         \n [91] \"ellas\"        \"nosotras\"     \"vosotros\"     \"vosotras\"     \"os\"          \n [96] \"m√≠o\"          \"m√≠a\"          \"m√≠os\"         \"m√≠as\"         \"tuyo\"        \n[101] \"tuya\"         \"tuyos\"        \"tuyas\"        \"suyo\"         \"suya\"        \n[106] \"suyos\"        \"suyas\"        \"nuestro\"      \"nuestra\"      \"nuestros\"    \n[111] \"nuestras\"     \"vuestro\"      \"vuestra\"      \"vuestros\"     \"vuestras\"    \n[116] \"esos\"         \"esas\"         \"estoy\"        \"est√°s\"        \"est√°\"        \n[121] \"estamos\"      \"est√°is\"       \"est√°n\"        \"est√©\"         \"est√©s\"       \n[126] \"estemos\"      \"est√©is\"       \"est√©n\"        \"estar√©\"       \"estar√°s\"     \n[131] \"estar√°\"       \"estaremos\"    \"estar√©is\"     \"estar√°n\"      \"estar√≠a\"     \n[136] \"estar√≠as\"     \"estar√≠amos\"   \"estar√≠ais\"    \"estar√≠an\"     \"estaba\"      \n[141] \"estabas\"      \"est√°bamos\"    \"estabais\"     \"estaban\"      \"estuve\"      \n[146] \"estuviste\"    \"estuvo\"       \"estuvimos\"    \"estuvisteis\"  \"estuvieron\"  \n[151] \"estuviera\"    \"estuvieras\"   \"estuvi√©ramos\" \"estuvierais\"  \"estuvieran\"  \n[156] \"estuviese\"    \"estuvieses\"   \"estuvi√©semos\" \"estuvieseis\"  \"estuviesen\"  \n[161] \"estando\"      \"estado\"       \"estada\"       \"estados\"      \"estadas\"     \n[166] \"estad\"        \"he\"           \"has\"          \"ha\"           \"hemos\"       \n[171] \"hab√©is\"       \"han\"          \"haya\"         \"hayas\"        \"hayamos\"     \n[176] \"hay√°is\"       \"hayan\"        \"habr√©\"        \"habr√°s\"       \"habr√°\"       \n[181] \"habremos\"     \"habr√©is\"      \"habr√°n\"       \"habr√≠a\"       \"habr√≠as\"     \n[186] \"habr√≠amos\"    \"habr√≠ais\"     \"habr√≠an\"      \"hab√≠a\"        \"hab√≠as\"      \n[191] \"hab√≠amos\"     \"hab√≠ais\"      \"hab√≠an\"       \"hube\"         \"hubiste\"     \n[196] \"hubo\"         \"hubimos\"      \"hubisteis\"    \"hubieron\"     \"hubiera\"     \n[201] \"hubieras\"     \"hubi√©ramos\"   \"hubierais\"    \"hubieran\"     \"hubiese\"     \n[206] \"hubieses\"     \"hubi√©semos\"   \"hubieseis\"    \"hubiesen\"     \"habiendo\"    \n[211] \"habido\"       \"habida\"       \"habidos\"      \"habidas\"      \"soy\"         \n[216] \"eres\"         \"es\"           \"somos\"        \"sois\"         \"son\"         \n[221] \"sea\"          \"seas\"         \"seamos\"       \"se√°is\"        \"sean\"        \n[226] \"ser√©\"         \"ser√°s\"        \"ser√°\"         \"seremos\"      \"ser√©is\"      \n[231] \"ser√°n\"        \"ser√≠a\"        \"ser√≠as\"       \"ser√≠amos\"     \"ser√≠ais\"     \n[236] \"ser√≠an\"       \"era\"          \"eras\"         \"√©ramos\"       \"erais\"       \n[241] \"eran\"         \"fui\"          \"fuiste\"       \"fue\"          \"fuimos\"      \n[246] \"fuisteis\"     \"fueron\"       \"fuera\"        \"fueras\"       \"fu√©ramos\"    \n[251] \"fuerais\"      \"fueran\"       \"fuese\"        \"fueses\"       \"fu√©semos\"    \n[256] \"fueseis\"      \"fuesen\"       \"siendo\"       \"sido\"         \"tengo\"       \n[261] \"tienes\"       \"tiene\"        \"tenemos\"      \"ten√©is\"       \"tienen\"      \n[266] \"tenga\"        \"tengas\"       \"tengamos\"     \"teng√°is\"      \"tengan\"      \n[271] \"tendr√©\"       \"tendr√°s\"      \"tendr√°\"       \"tendremos\"    \"tendr√©is\"    \n[276] \"tendr√°n\"      \"tendr√≠a\"      \"tendr√≠as\"     \"tendr√≠amos\"   \"tendr√≠ais\"   \n[281] \"tendr√≠an\"     \"ten√≠a\"        \"ten√≠as\"       \"ten√≠amos\"     \"ten√≠ais\"     \n[286] \"ten√≠an\"       \"tuve\"         \"tuviste\"      \"tuvo\"         \"tuvimos\"     \n[291] \"tuvisteis\"    \"tuvieron\"     \"tuviera\"      \"tuvieras\"     \"tuvi√©ramos\"  \n[296] \"tuvierais\"    \"tuvieran\"     \"tuviese\"      \"tuvieses\"     \"tuvi√©semos\"  \n[301] \"tuvieseis\"    \"tuviesen\"     \"teniendo\"     \"tenido\"       \"tenida\"      \n[306] \"tenidos\"      \"tenidas\"      \"tened\"       \n```\n:::\n\n```{.r .cell-code}\n# - Remove stopwords\nstop_words_en <- stopwords(\"en\")\nstop_words_es <- stopwords(\"es\")\nbukele_toks <- tokens_remove(bukele_toks, pattern = stop_words_en)\nbukele_toks <- tokens_remove(bukele_toks, pattern = stop_words_es)\n\n# - Create a new dfm after removing stopwords\nbukele_dfm <- dfm(bukele_toks)\n\n# - Display the new number of features\nnfeat(bukele_dfm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 25273\n```\n:::\n\n```{.r .cell-code}\n# Step 13: Define terms for the bitcoin and maras variables\n\n# - Define terms for bitcoin and maras\nbitcoin_terms <- c(\"bitcoin\", \"btc\", \"#bitcoin\", \"@bitcoinmagazine\", \"crypto\", \"cripto\", \n                   \"chivo wallet\", \"chivo\", \"blockchain\", \"buy the dip\", \"dip\")\n\nmaras_terms <- c(\"mara\", \"pandilla\", \"pandillas\", \"maras\", \"criminales\", \"criminal\", \n                 \"MS-13\", \"CECOT\", \"terrorismo\", \"seguridad\", \"regimen\", \"excepcion\", \n                 \"gang\", \"salvatrucha\", \"mano dura\", \"pct\", \"plan de control territorial\")\n\n# - Create new variables using grepl\nbukele$bitcoin <- as.numeric(grepl(paste(bitcoin_terms, collapse = \"|\"), bukele$text, ignore.case = TRUE))\nbukele$maras <- as.numeric(grepl(paste(maras_terms, collapse = \"|\"), bukele$text, ignore.case = TRUE))\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}